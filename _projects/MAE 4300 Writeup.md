---
layout: project
title: MAE 4300 Writeup
description: End of Semester Class project 
image: /assets/images/747.jpg
---
Introduction
 Throughout this course, I focused on understanding how technical decisions, organizational structures, and individual actions all work together to create real world consequences. The main case study that our class looked at was the Boeing 747 Max crisis, and what decisions and structures lead to this failure. I found that although it’s easy to blame the engineers who designed the MCAS system, there are actually many more layers than I thought. The failure involved so many different stakeholders such as management, regulators, engineers, and more that all played a role in this disaster. For several weeks, we analyzed and identified these stakeholders and each of their individual roles.

Identifying Ethical Issues
 In week 6 of the course I conducted an ethical analysis on this case study. I identified key ethical questions, related these questions to professional codes and responsibilities, and dove deeper into five of these issues. I tried to look at several perspectives and think of justifications and other pressures that would lead these stakeholders into making these specific decisions. I raised questions on whether Boeing should have required additional pilot training despite the cost and schedule pressures, whether MCAS should have relied on a single angle of attack sensor, whether safety critical system details should have been disclosed more transparently to pilots, airlines, and regulators. All of these issues had their own ethical challenges such as technical design decisions, company specific priorities, public trust, questions of transparency and more. I learned that these ethical dilemmas were much more layered and nuanced than I thought.

In the next week, I focused on the same issues and determining facts, assumptions, and definitional clarifications. In order to fully analyze issues, it’s important to get the relevant facts correct. I categorized the information into material, individual, and organizational facts. Material facts focus on design decisions, individual facts focus on personal actions, and organizational facts focus on policies, culture, and corporate elements. A material fact for example included the MCAS reliance on a single sensor. An individual fact focused on the actions of the Boeing engineers and pilots. Organizational facts were about Boeing's internal culture, competitive pressures against Airbus, cost and schedule incentives and FAA requirements. This confirmed that this problem could not be narrowed down to one individual’s mistake, that it was a combination of individual, material, and organizational failures. While it’s good to look at facts, it's equally as important to look at missing facts and make assumptions about why stakeholders made the decisions they did. One of my assumptions was that Boeing engineers recognized risks but lacked the support to raise concerns. When isolating each stakeholder’s decisions it’s important to try and contextualize their decisions by guessing how they defined terms such as safety, accountability, transparency and risk. For example, Boeing may have defined success as meeting their deadlines and making money, however the FAA defines success as fully regulating all aircrafts. It's obvious that different stakeholders have different definitions for the same thing, so seeing how these definitions conflict with each other can tell us a lot about the situation.

In week 8, I continued this ethical analysis by focusing on the ASME codes and identifying these conflicts between employer loyalty and public safety. In each case I came to the conclusion that public safety must always take priority over anything such as cost, schedule, or competitive pressures. I argued that Boeing engineers and the FAA should have delayed the certification until MCAS was implemented properly and proper pilot training was done.

In the last week of taking a deep dive in this case, I focused on how these ethical issues may have been prevented. I examined and identified practical constraints for my five issues. For each constraint I came up with ways that may have prevented engineers from taking the ideal ethical action. After this, I proposed strategies at the individual, organizational, and systemic level that may have prevented the disaster. For example, one strategy was to enforce whistleblower protection that may have helped to encourage engineers with concerns to raise them publicly. I also suggested more organizational transparency measures meaning Boeing should have been required to publish their new designs publicly, and MCAS should have been taught to pilots and in the new manuals at the least. I also suggested that all employers needed to have stronger ethics training along with more support to speak up. At the organizational level, Boeing needed to have clearer and better safety protocols, and at the systemic level, regulators should always enforce immediate investigations on crashes and planes to stop the same mistake from happening twice.

Overall, my work progressed from identifying ethical concerns to analyzing the systemic causes, leading me to outline specific strategies that may have prevented the Boeing 747 Max tragedy. This course has opened my eyes to the ethical responsibility that engineers have to society, and that technical decisions that engineers make can have many serious consequences so must not be taken lightly.







